{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3d8a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33e84a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27cb46ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification, pipeline\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"arpanghoshal/EmoRoBERTa\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"arpanghoshal/EmoRoBERTa\", from_tf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_float(num):\n",
    "    return np.format_float_positional(num, trim='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "20d9605c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"happy, sad, angry, pissed\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "probabilities_scores = F.softmax(logits, dim = -1).numpy()\n",
    "probabilities_scores = [format_float(s) for s in probabilities_scores[0]]\n",
    "\n",
    "model.config.id2label[np.argmax(probabilities_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c376aeb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
